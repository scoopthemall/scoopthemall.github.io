<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Gotta Scoop 'Em All: Sim-and-Real Co-Training of Graph-based Neural Dynamics for Long-Horizon Scooping</title>
</head>
<body>

<h1>Gotta Scoop 'Em All: Sim-and-Real Co-Training of Graph-based Neural Dynamics for Long-Horizon Scooping</h1>

<section id="teaser">
  <object data="./static/images/teaser.pdf" type="application/pdf" width="100%" height="600">
    <p>Your browser can't display PDFs. <a href="./static/images/teaser.pdf">Download the teaser PDF</a>.</p>
  </object>
  
  
</section>

<section id="abstract">
  <h2>Abstract</h2>
  <p>
    We present a system to address a new problem of removing all granular objects from a container using a scoop, a task that requires long-horizon reasoning over the complex interactions between granular objects, the scoop, and the container. To tackle this challenge, we adopt a graph-based neural dynamics (GBND) model trained through sim-and-real co-training that leverages both rich synthetic data and a small amount of real-world data.
  </p>
  <p>
    Using the learned model, we plan long-horizon scooping sequences of behavior primitives with Monte-carlo Tree Search (MCTS).
  </p>
  <p>
    Extensive experimental evaluations demonstrate that our system with the co-training strategy is capable of removing all materials in a container with fewer than 20 scoops, significantly outperforming strategies that use only simulation or real data. Our approach can also generalize in a zero-shot manner to new materials, and quickly adapt to new containers with few additional data points.
  </p>
</section>

<section id="video">
  <h2>Video</h2>
  <div>
    <iframe width="100%" height="480" src="https://www.youtube.com/embed/MM_xyRnbXmk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
  </div>
</section>

</body>
</html>


